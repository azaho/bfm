{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the config and the subject data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:48:33 gpu 0.0G ram 0.5G] (0) Directory name: EEG-IEEG_nst1_dm192_nh12_nl5_5_eaM_eeL_fb1_cls_lr0.003_rTEMP\n",
      "[12:48:33 gpu 0.0G ram 0.5G] (0) Using device: cuda\n",
      "[12:48:33 gpu 0.0G ram 0.5G] (0) Loading subjects...\n",
      "[12:48:33 gpu 0.0G ram 0.5G] (1)     loading subject mgh1...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import wandb, os, json\n",
    "import time\n",
    "\n",
    "from muon import Muon\n",
    "from model_model import TransformerModel\n",
    "from model_electrode_embedding import ElectrodeEmbedding_Learned, ElectrodeEmbedding_Learned_FixedVocabulary\n",
    "from model_electrode_embedding import ElectrodeDataEmbeddingFFT, ElectrodeDataEmbedding\n",
    "\n",
    "from dataset import load_dataloaders, load_subjects\n",
    "from evaluation_btbench import FrozenModelEvaluation_SS_SM\n",
    "from train_utils import log, update_dir_name, update_random_seed, convert_dtypes, parse_configs_from_args, get_default_configs, get_shared_memory_info\n",
    "\n",
    "training_config, model_config, cluster_config = get_default_configs(random_string=\"TEMP\", wandb_project=\"\")\n",
    "\n",
    "# This is to be used to parse the command line arguments\n",
    "# parse_configs_from_args(training_config, model_config, cluster_config)\n",
    "# Instead, for now just hardcode the configs\n",
    "training_config['train_subject_trials'] = [('mgh1', 3)] #[('mgh1', 3), ('mgh1', 2)]\n",
    "training_config['eval_subject_trials'] = []\n",
    "cluster_config['eval_model_every_n_epochs'] = 3\n",
    "cluster_config['cache_subjects'] = True\n",
    "model_config['name'] = 'EEG-IEEG'\n",
    "\n",
    "# EEG channel names\n",
    "EEG_channels = ['Fp1', 'Fp2', 'F3', 'Fz', 'F4', 'C3', 'Cz', 'C4', 'P3', 'Pz', 'P4', 'O1', 'O2', 'F7', 'F8', 'T3', 'T4', 'T5', 'T6']\n",
    "\n",
    "dir_name = update_dir_name(model_config, training_config, cluster_config)\n",
    "update_random_seed(training_config)\n",
    "cluster_config['wandb_name'] = cluster_config['dir_name']\n",
    "log(f\"Directory name: {dir_name}\", priority=0)\n",
    "\n",
    "if len(cluster_config['wandb_project'])==0: wandb = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "log(f\"Using device: {device}\", priority=0)\n",
    "\n",
    "log(f\"Loading subjects...\", priority=0)\n",
    "all_subjects = load_subjects(training_config['train_subject_trials'], training_config['eval_subject_trials'], training_config['data_dtype'], \n",
    "                             cache=cluster_config['cache_subjects'], allow_corrupted=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:48:33 gpu 0.0G ram 0.5G] (1)     loading dataset for mgh1_3...\n",
      "[12:49:11 gpu 0.0G ram 7.1G] (1)     finished loading dataset for mgh1_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/vast-storage/scratch/vast/yanglab/zaho/bfm_ic2/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, test_dataloader = load_dataloaders(\n",
    "    all_subjects, training_config['train_subject_trials'], training_config['p_test'], \n",
    "    model_config['sample_timebin_size'], model_config['max_n_timebins'], training_config['data_dtype'], \n",
    "    training_config['batch_size'],\n",
    "    num_workers_dataloaders=cluster_config['num_workers_dataloaders'], \n",
    "    prefetch_factor=cluster_config['prefetch_factor'],\n",
    "    max_n_electrodes=model_config['max_n_electrodes'],\n",
    "    output_embeddings_map=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_i, batch = 0, train_dataloader[0]\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model_config['electrode_embedding']['type'] in ['learned', 'zero'] # only those two are supported for now; we don't have coordinates for MGH data.\n",
    "\n",
    "electrode_embeddings = ElectrodeEmbedding_Learned(\n",
    "    model_config['transformer']['d_model'], \n",
    "    embedding_dim=model_config['electrode_embedding']['embedding_dim'],\n",
    "    embedding_requires_grad=model_config['electrode_embedding']['type'] != 'zero' # if zero, the embedding is not learned and fixed at zero\n",
    ")\n",
    "\n",
    "electrode_embeddings_eeg = ElectrodeEmbedding_Learned_FixedVocabulary(\n",
    "    model_config['transformer']['d_model'], \n",
    "    embedding_dim=model_config['electrode_embedding']['embedding_dim'],\n",
    "    embedding_requires_grad=model_config['electrode_embedding']['type'] != 'zero' # if zero, the embedding is not learned and fixed at zero\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bfm_ic2 (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
