{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:13:28 gpu 16.2G ram 2.6G] Using device: cuda\n",
      "[21:13:28 gpu 16.2G ram 2.6G] Loading model from models_data/M_nst1_dm192_nh12_nl5_5_nes50_nf_nII_nSP_mxt8_eeL_fb1_cls_lr0.003_rTEMP_lrL_ws100/model_epoch_20.pth\n",
      "[21:13:30 gpu 16.2G ram 2.6G] Model parameters: 5,576,962\n",
      "[21:13:30 gpu 16.2G ram 2.6G] Embedding parameters: 19,200\n",
      "[21:13:30 gpu 16.2G ram 2.6G] Total parameters: 5,596,162\n",
      "[21:13:30 gpu 16.2G ram 2.6G] Evaluation results at epoch 20:\n",
      "[21:13:30 gpu 16.2G ram 2.6G]   train_contrastive_x: 0.0084\n",
      "[21:13:30 gpu 16.2G ram 2.6G]   train_accuracy_x: 0.0081\n",
      "[21:13:30 gpu 16.2G ram 2.6G]   test_contrastive_x: 2.6661\n",
      "[21:13:30 gpu 16.2G ram 2.6G]   test_accuracy_x: 0.4271\n",
      "[21:13:30 gpu 16.2G ram 2.6G]   eval_auroc/average_gpt2_surprisal: 0.5774\n",
      "[21:13:30 gpu 16.2G ram 2.6G]   eval_auroc/average_volume: 0.6154\n",
      "[21:13:30 gpu 16.2G ram 2.6G]   eval_auroc/average_word_part_speech: 0.5197\n",
      "[21:13:30 gpu 16.2G ram 2.6G]   eval_auroc/average_pitch: 0.5364\n",
      "[21:13:30 gpu 16.2G ram 2.6G]   eval_auroc/average_speech: 0.9286\n",
      "[21:13:30 gpu 16.2G ram 2.6G] Model successfully loaded from epoch 20\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from train_utils import get_default_configs, unconvert_dtypes, log, update_dir_name\n",
    "from model_model import GranularModel, BinTransformer, CrossModel\n",
    "from model_electrode_embedding import ElectrodeEmbedding_Learned, ElectrodeEmbedding_NoisyCoordinate, ElectrodeEmbedding_Learned_CoordinateInit\n",
    "\n",
    "# Get default configs\n",
    "training_config, model_config, cluster_config = get_default_configs(random_string=\"TEMP\", wandb_project=\"\")\n",
    "cluster_config['num_workers_dataloaders'] = 2\n",
    "cluster_config['num_workers_eval'] = 2\n",
    "model_config['init_identity'] = False\n",
    "\n",
    "dir_name = update_dir_name(model_config, training_config, cluster_config)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "log(f\"Using device: {device}\", priority=0)\n",
    "\n",
    "# Specify the model directory and epoch to load\n",
    "model_dir = f\"models_data/{dir_name}\"  # Replace with your actual model directory name\n",
    "epoch_to_load = 20\n",
    "\n",
    "# Load the saved model checkpoint\n",
    "checkpoint_path = f\"{model_dir}/model_epoch_{epoch_to_load}.pth\"\n",
    "log(f\"Loading model from {checkpoint_path}\", priority=0)\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "# Update configs from the saved checkpoint\n",
    "saved_training_config = unconvert_dtypes(checkpoint['training_config'])\n",
    "saved_model_config = unconvert_dtypes(checkpoint['model_config'])\n",
    "saved_cluster_config = unconvert_dtypes(checkpoint['cluster_config'])\n",
    "\n",
    "# Merge configs (use saved configs)\n",
    "training_config.update(saved_training_config)\n",
    "model_config.update(saved_model_config)\n",
    "cluster_config.update(saved_cluster_config)\n",
    "\n",
    "# Initialize model components\n",
    "bin_transformer = BinTransformer(\n",
    "    first_kernel=int(model_config['sample_timebin_size']*2048)//16, \n",
    "    d_model=192,\n",
    "    n_layers=2,\n",
    "    n_heads=4,\n",
    "    overall_sampling_rate=2048,\n",
    "    sample_timebin_size=model_config['sample_timebin_size'],\n",
    "    n_downsample_factor=1,\n",
    "    identity_init=model_config['init_identity']\n",
    ").to(device, dtype=model_config['dtype'])\n",
    "\n",
    "model = GranularModel(\n",
    "    int(model_config['sample_timebin_size'] * 2048),\n",
    "    model_config['transformer']['d_model'],  \n",
    "    n_layers=model_config['transformer']['n_layers_time'],\n",
    "    n_heads=model_config['transformer']['n_heads'],\n",
    "    identity_init=model_config['init_identity']\n",
    ").to(device, dtype=model_config['dtype'])\n",
    "\n",
    "cross_model = CrossModel(\n",
    "    int(model_config['sample_timebin_size'] * 2048),\n",
    "    model_config['transformer']['d_model'],\n",
    "    n_layers=model_config['transformer']['n_layers_electrode'],\n",
    "    n_heads=model_config['transformer']['n_heads'],\n",
    ").to(device, dtype=model_config['dtype'])\n",
    "\n",
    "# Initialize electrode embeddings based on the type\n",
    "if model_config['electrode_embedding']['type'] == 'learned' or model_config['electrode_embedding']['type'] == 'zero':\n",
    "    electrode_embeddings = ElectrodeEmbedding_Learned(\n",
    "        model_config['transformer']['d_model'], \n",
    "        embedding_dim=model_config['electrode_embedding']['embedding_dim'],\n",
    "        embedding_requires_grad=model_config['electrode_embedding']['type'] != 'zero'\n",
    "    )\n",
    "elif model_config['electrode_embedding']['type'] == 'coordinate_init':\n",
    "    electrode_embeddings = ElectrodeEmbedding_Learned_CoordinateInit(\n",
    "        model_config['transformer']['d_model'], \n",
    "        embedding_dim=model_config['electrode_embedding']['embedding_dim']\n",
    "    )\n",
    "elif model_config['electrode_embedding']['type'] == 'noisy_coordinate':\n",
    "    electrode_embeddings = ElectrodeEmbedding_NoisyCoordinate(\n",
    "        model_config['transformer']['d_model'], \n",
    "        coordinate_noise_std=model_config['electrode_embedding']['coordinate_noise_std'],\n",
    "        embedding_dim=model_config['electrode_embedding']['embedding_dim']\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"Invalid electrode embedding type: {model_config['electrode_embedding']['type']}\")\n",
    "electrode_embeddings = electrode_embeddings.to(device, dtype=model_config['dtype'])\n",
    "\n",
    "# Load state dictionaries from checkpoint\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "bin_transformer.load_state_dict(checkpoint['bin_transformer_state_dict'])\n",
    "cross_model.load_state_dict(checkpoint['cross_model_state_dict'])\n",
    "electrode_embeddings.load_state_dict(checkpoint['electrode_embeddings_state_dict'])\n",
    "\n",
    "# Set models to evaluation mode\n",
    "model.eval()\n",
    "bin_transformer.eval()\n",
    "cross_model.eval()\n",
    "electrode_embeddings.eval()\n",
    "\n",
    "# Print model information\n",
    "n_model_params = sum(p.numel() for p in model.parameters()) + sum(p.numel() for p in bin_transformer.parameters()) + sum(p.numel() for p in cross_model.parameters())\n",
    "n_embed_params = sum(p.numel() for p in electrode_embeddings.parameters())\n",
    "log(f\"Model parameters: {n_model_params:,}\", priority=0)\n",
    "log(f\"Embedding parameters: {n_embed_params:,}\", priority=0)\n",
    "log(f\"Total parameters: {n_model_params + n_embed_params:,}\", priority=0)\n",
    "\n",
    "# Print evaluation results from checkpoint\n",
    "log(f\"Evaluation results at epoch {epoch_to_load}:\", priority=0)\n",
    "for key, value in checkpoint['eval_results'].items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        log(f\"  {key}: {value:.4f}\", priority=0)\n",
    "    else:\n",
    "        log(f\"  {key}: {value}\", priority=0)\n",
    "\n",
    "# Now the model is loaded and ready to use\n",
    "log(f\"Model successfully loaded from epoch {epoch_to_load}\", priority=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:07:53 gpu 0.0G ram 0.7G] Loading subjects for evaluation...\n",
      "[21:07:53 gpu 0.0G ram 0.7G]     loading subject btbank3...\n",
      "[21:07:53 gpu 0.0G ram 0.7G] Subject btbank3 has 21 temporal lobe electrodes\n",
      "[21:07:53 gpu 0.0G ram 0.7G] Adding subject btbank3 to electrode embeddings...\n",
      "[21:08:03 gpu 0.0G ram 1.5G] Running evaluation on loaded model...\n",
      "[21:08:03 gpu 0.0G ram 1.5G]     evaluating on all metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/vast-storage/scratch/vast/yanglab/zaho/bfm_ic2/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/net/vast-storage/scratch/vast/yanglab/zaho/bfm_ic2/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/net/vast-storage/scratch/vast/yanglab/zaho/bfm_ic2/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/net/vast-storage/scratch/vast/yanglab/zaho/bfm_ic2/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/net/vast-storage/scratch/vast/yanglab/zaho/bfm_ic2/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:10:46 gpu 16.2G ram 2.6G]     done evaluating on all metrics\n",
      "{'eval_auroc/average_gpt2_surprisal': 0.6562908496732025, 'eval_auroc/average_volume': 0.6157898224224754, 'eval_auroc/average_word_part_speech': 0.5658141739308217, 'eval_auroc/average_pitch': 0.5683403247806058, 'eval_auroc/average_speech': 0.8377959183673469}\n"
     ]
    }
   ],
   "source": [
    "from dataset import load_subjects\n",
    "from evaluation_btbench import FrozenModelEvaluation_SS_SM\n",
    "# Load subjects for evaluation\n",
    "log(f\"Loading subjects for evaluation...\", priority=0)\n",
    "all_subjects = load_subjects(training_config['train_subject_trials'], training_config['eval_subject_trials'], training_config['data_dtype'], \n",
    "                             cache=cluster_config['cache_subjects'], allow_corrupted=False)\n",
    "\n",
    "# Set electrode subset for each subject (temporal lobe electrodes)\n",
    "from btbench.btbench_config import BTBENCH_LITE_ELECTRODES\n",
    "for subject_identifier, subject in all_subjects.items():\n",
    "    consider_electrode_names = list(BTBENCH_LITE_ELECTRODES[subject_identifier])\n",
    "    electrode_subset = [electrode_label for electrode_label in consider_electrode_names if electrode_label.startswith('T')]\n",
    "    subject.set_electrode_subset(electrode_subset)\n",
    "    log(f\"Subject {subject_identifier} has {len(electrode_subset)} temporal lobe electrodes\", priority=0)\n",
    "\n",
    "# Add subjects to electrode embeddings\n",
    "for subject in all_subjects.values():\n",
    "    log(f\"Adding subject {subject.subject_identifier} to electrode embeddings...\", priority=0)\n",
    "    this_subject_trials = [trial_id for (sub_id, trial_id) in training_config['train_subject_trials'] if sub_id == subject.subject_identifier]\n",
    "    electrode_embeddings.add_subject(subject)\n",
    "electrode_embeddings = electrode_embeddings.to(device, dtype=model_config['dtype'])\n",
    "\n",
    "# Define evaluation electrode subset if needed\n",
    "eval_electrode_subset = {\n",
    "    #'btbank3': ['T1cIe11'],\n",
    "}\n",
    "\n",
    "# Create evaluation object\n",
    "eval_subject_trials = [(all_subjects[subject_identifier], trial_id) for subject_identifier, trial_id in training_config['eval_subject_trials']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import sklearn.metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from btbench.btbench_train_test_splits import generate_splits_SS_SM\n",
    "from btbench.btbench_config import BTBENCH_LITE_ELECTRODES\n",
    "from train_utils import log\n",
    "import torch\n",
    "\n",
    "# Evaluation class for Same Subject Same Movie (SS-SM), on btbench evals\n",
    "class FrozenModelEvaluation_SS_SM():\n",
    "    def __init__(self, eval_names, subject_trials, dtype, batch_size, embeddings_map,\n",
    "                 num_workers_eval=4, prefetch_factor=2,\n",
    "                 feature_aggregation_method='concat', # 'mean', 'concat'\n",
    "                 # regression parameters\n",
    "                 regression_random_state=42,  regression_solver='lbfgs', \n",
    "                 regression_tol=1e-3,\n",
    "                 regression_max_iter=10000,\n",
    "                 lite=True, electrode_subset=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            eval_names (list): List of evaluation metric names to use (e.g. [\"volume\", \"word_gap\"])\n",
    "            subject_trials (list): List of tuples where each tuple contains (subject, trial_id).\n",
    "                                 subject is a BrainTreebankSubject object and trial_id is an integer.\n",
    "            dtype (torch.dtype, optional): Data type for tensors.\n",
    "        \"\"\"\n",
    "        self.eval_names = eval_names\n",
    "        self.subject_trials = subject_trials\n",
    "        self.all_subjects = set([subject for subject, trial_id in self.subject_trials])\n",
    "        self.all_subject_identifiers = set([subject.subject_identifier for subject in self.all_subjects])\n",
    "        self.dtype = dtype\n",
    "        self.batch_size = batch_size\n",
    "        self.lite = lite\n",
    "        \n",
    "        self.feature_aggregation_method = feature_aggregation_method\n",
    "\n",
    "        self.regression_max_iter = regression_max_iter\n",
    "        self.regression_random_state = regression_random_state\n",
    "        self.regression_solver = regression_solver\n",
    "        self.regression_tol = regression_tol\n",
    "        self.num_workers_eval = num_workers_eval\n",
    "        self.prefetch_factor = prefetch_factor\n",
    "\n",
    "        self.evaluation_datasets = {}\n",
    "        for eval_name in self.eval_names:\n",
    "            for subject, trial_id in self.subject_trials:\n",
    "                splits = generate_splits_SS_SM(subject, trial_id, eval_name, dtype=self.dtype, lite=self.lite, start_neural_data_before_word_onset=0, end_neural_data_after_word_onset=2048)\n",
    "                self.evaluation_datasets[(eval_name, subject.subject_identifier, trial_id)] = splits\n",
    "                \n",
    "        self.all_subject_electrode_indices = {}\n",
    "        for subject in self.all_subjects:\n",
    "            self.all_subject_electrode_indices[subject.subject_identifier] = []\n",
    "            for electrode_label in BTBENCH_LITE_ELECTRODES[subject.subject_identifier] if self.lite else subject.get_electrode_labels():\n",
    "                key = (subject.subject_identifier, electrode_label)\n",
    "                if key in embeddings_map: # If the electrodes were subset to exclude this one, ignore it\n",
    "                    self.all_subject_electrode_indices[subject.subject_identifier].append(embeddings_map[key])\n",
    "            self.all_subject_electrode_indices[subject.subject_identifier] = torch.tensor(self.all_subject_electrode_indices[subject.subject_identifier])\n",
    "        \n",
    "        # XXX Surely there is a better way to do this\n",
    "        self.all_subject_electrode_subset_indices = None\n",
    "        if electrode_subset is not None:\n",
    "            self.all_subject_electrode_subset_indices = {}\n",
    "            for subject in self.all_subjects:\n",
    "                if subject.subject_identifier not in electrode_subset:\n",
    "                    continue\n",
    "                self.all_subject_electrode_subset_indices[subject.subject_identifier] = []\n",
    "                for electrode_label in electrode_subset[subject.subject_identifier]:\n",
    "                    key = (subject.subject_identifier, electrode_label)\n",
    "                    if key in embeddings_map: # If the electrodes were subset to exclude this one, ignore it\n",
    "                        self.all_subject_electrode_subset_indices[subject.subject_identifier].append(list(self.all_subject_electrode_indices[subject.subject_identifier]).index(embeddings_map[key]))\n",
    "                self.all_subject_electrode_subset_indices[subject.subject_identifier] = torch.tensor(self.all_subject_electrode_subset_indices[subject.subject_identifier])\n",
    "\n",
    "    def _evaluate_on_dataset(self, model, bin_transformer, electrode_embeddings, subject, train_dataset, test_dataset, log_priority=0):\n",
    "        subject_identifier = subject.subject_identifier\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers_eval, \n",
    "                                      prefetch_factor=self.prefetch_factor, pin_memory=True)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers_eval, \n",
    "                                      prefetch_factor=self.prefetch_factor, pin_memory=True)\n",
    "        device, dtype = model.device, model.dtype\n",
    "        X_train, y_train = [], []\n",
    "        log('generating frozen train features', priority=log_priority, indent=2)\n",
    "        for i, (batch_input, batch_label) in enumerate(train_dataloader):\n",
    "            log(f'generating frozen features for batch {i} of {len(train_dataloader)}', priority=log_priority, indent=3)\n",
    "            batch_input = batch_input.to(device, dtype=dtype, non_blocking=True) # shape (batch_size, n_electrodes, n_samples)\n",
    "            if self.all_subject_electrode_subset_indices is not None and subject_identifier in self.all_subject_electrode_subset_indices:\n",
    "                batch_input = batch_input[:, self.all_subject_electrode_subset_indices[subject_identifier], :]\n",
    "\n",
    "            # normalize the data\n",
    "            batch_input = batch_input - torch.mean(batch_input, dim=[0, 2], keepdim=True)\n",
    "            batch_input = batch_input / (torch.std(batch_input, dim=[0, 2], keepdim=True) + 1)\n",
    "            #electrode_data = batch_input.reshape(bin_transformer(batch_input).shape) # \n",
    "            electrode_data = bin_transformer(batch_input) # shape (batch_size, n_electrodes, n_samples)\n",
    "\n",
    "            electrode_indices = self.all_subject_electrode_indices[subject_identifier].to(device, dtype=torch.long, non_blocking=True)\n",
    "            electrode_indices = electrode_indices.unsqueeze(0).expand(batch_input.shape[0], -1) # Add the batch dimension to the electrode indices\n",
    "            if self.all_subject_electrode_subset_indices is not None and subject_identifier in self.all_subject_electrode_subset_indices:\n",
    "                electrode_indices = electrode_indices[:, self.all_subject_electrode_subset_indices[subject_identifier]]\n",
    "\n",
    "            embeddings = electrode_embeddings.forward(electrode_indices)\n",
    "            \n",
    "            features = model.generate_frozen_evaluation_features(electrode_data, embeddings, feature_aggregation_method=self.feature_aggregation_method)\n",
    "\n",
    "            #features = electrode_data.reshape(batch_input.shape[0], -1)\n",
    "            \n",
    "            #features = batch_input.reshape(batch_input.shape[0], -1)\n",
    "            #features = electrode_embedded_data.reshape(batch_input.shape[0], -1)\n",
    "            log(f'done generating frozen features for batch {i} of {len(train_dataloader)}', priority=log_priority, indent=3)\n",
    "            X_train.append(features.detach().cpu().float().numpy())\n",
    "            y_train.append(batch_label.numpy())\n",
    "\n",
    "        X_test, y_test = [], []\n",
    "        log('generating frozen test features', priority=log_priority, indent=2)\n",
    "        for i, (batch_input, batch_label) in enumerate(test_dataloader):\n",
    "            log(f'generating frozen features for batch {i} of {len(test_dataloader)}', priority=log_priority, indent=3)\n",
    "            batch_input = batch_input.to(device, dtype=dtype, non_blocking=True)\n",
    "            if self.all_subject_electrode_subset_indices is not None and subject_identifier in self.all_subject_electrode_subset_indices:\n",
    "                batch_input = batch_input[:, self.all_subject_electrode_subset_indices[subject_identifier], :]\n",
    "\n",
    "            # normalize the data\n",
    "            batch_input = batch_input - torch.mean(batch_input, dim=[0, 2], keepdim=True)\n",
    "            batch_input = batch_input / (torch.std(batch_input, dim=[0, 2], keepdim=True) + 1)\n",
    "            #electrode_data = batch_input.reshape(bin_transformer(batch_input).shape) # bin_transformer(batch_input) # shape (batch_size, n_electrodes, n_samples)\n",
    "            electrode_data = bin_transformer(batch_input) # shape (batch_size, n_electrodes, n_samples)\n",
    "\n",
    "            electrode_indices = self.all_subject_electrode_indices[subject_identifier].to(device, dtype=torch.long, non_blocking=True)\n",
    "            electrode_indices = electrode_indices.unsqueeze(0).expand(batch_input.shape[0], -1) # Add the batch dimension to the electrode indices\n",
    "            if self.all_subject_electrode_subset_indices is not None and subject_identifier in self.all_subject_electrode_subset_indices:\n",
    "                electrode_indices = electrode_indices[:, self.all_subject_electrode_subset_indices[subject_identifier]]\n",
    "\n",
    "            embeddings = electrode_embeddings.forward(electrode_indices)\n",
    "\n",
    "            features = model.generate_frozen_evaluation_features(electrode_data, embeddings, feature_aggregation_method=self.feature_aggregation_method)\n",
    "\n",
    "            #features = electrode_data.reshape(batch_input.shape[0], -1)\n",
    "\n",
    "            #features = batch_input.reshape(batch_input.shape[0], -1)\n",
    "            #features = electrode_embedded_data.reshape(batch_input.shape[0], -1)\n",
    "            log(f'done generating frozen features for batch {i} of {len(test_dataloader)}', priority=log_priority, indent=3)\n",
    "            X_test.append(features.detach().cpu().float().numpy())\n",
    "            y_test.append(batch_label.numpy())\n",
    "        log('done generating frozen features', priority=log_priority, indent=2)\n",
    "\n",
    "        log(\"creating numpy arrays\", priority=log_priority, indent=2)\n",
    "        X_train = np.concatenate(X_train)\n",
    "        y_train = np.concatenate(y_train)\n",
    "        X_test = np.concatenate(X_test)\n",
    "        y_test = np.concatenate(y_test)\n",
    "        log(\"done creating numpy arrays\", priority=log_priority, indent=2)\n",
    "\n",
    "        regressor = LogisticRegression(\n",
    "            random_state=self.regression_random_state, \n",
    "            max_iter=self.regression_max_iter, \n",
    "            n_jobs=self.num_workers_eval, \n",
    "            solver=self.regression_solver, \n",
    "            tol=self.regression_tol\n",
    "        )\n",
    "\n",
    "        # Standardize the features\n",
    "        log('standardizing features', priority=log_priority, indent=2)\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        log('fitting regressor', priority=log_priority, indent=2)\n",
    "        regressor.fit(X_train, y_train)\n",
    "        log('done fitting regressor', priority=log_priority, indent=2)\n",
    "\n",
    "        # Get predictions for multiclass classification\n",
    "        train_probs = regressor.predict_proba(X_train)\n",
    "        test_probs = regressor.predict_proba(X_test)\n",
    "\n",
    "        # Filter test samples to only include classes that were in training\n",
    "        valid_class_mask = np.isin(y_test, regressor.classes_)\n",
    "        y_test_filtered = y_test[valid_class_mask]\n",
    "        test_probs_filtered = test_probs[valid_class_mask]\n",
    "\n",
    "        # Convert to one-hot encoding\n",
    "        y_test_onehot = np.zeros((len(y_test_filtered), len(regressor.classes_)))\n",
    "        for i, label in enumerate(y_test_filtered):\n",
    "            class_idx = np.where(regressor.classes_ == label)[0][0]\n",
    "            y_test_onehot[i, class_idx] = 1\n",
    "\n",
    "        y_train_onehot = np.zeros((len(y_train), len(regressor.classes_)))\n",
    "        for i, label in enumerate(y_train):\n",
    "            class_idx = np.where(regressor.classes_ == label)[0][0]\n",
    "            y_train_onehot[i, class_idx] = 1\n",
    "\n",
    "        # Calculate ROC AUC based on number of classes\n",
    "        n_classes = len(regressor.classes_)\n",
    "        if n_classes > 2:\n",
    "            auroc = sklearn.metrics.roc_auc_score(y_test_onehot, test_probs_filtered, multi_class='ovr', average='macro')\n",
    "        else:\n",
    "            auroc = sklearn.metrics.roc_auc_score(y_test_onehot, test_probs_filtered)\n",
    "\n",
    "        accuracy = regressor.score(X_test, y_test)\n",
    "        log('done evaluating', priority=log_priority, indent=2)\n",
    "        return auroc, accuracy\n",
    "    \n",
    "    def _evaluate_on_metric_cv(self, model, bin_transformer, electrode_embeddings, subject, train_datasets, test_datasets, log_priority=0, quick_eval=False):\n",
    "        auroc_list, accuracy_list = [], []\n",
    "        for train_dataset, test_dataset in zip(train_datasets, test_datasets):\n",
    "            auroc, accuracy = self._evaluate_on_dataset(model, bin_transformer, electrode_embeddings, subject, train_dataset, test_dataset, log_priority=log_priority)\n",
    "            auroc_list.append(auroc)\n",
    "            accuracy_list.append(accuracy)\n",
    "            if quick_eval: break\n",
    "        return np.mean(auroc_list), np.mean(accuracy_list)\n",
    "    \n",
    "    def evaluate_on_all_metrics(self, model, bin_transformer, electrode_embeddings, log_priority=0, quick_eval=False, only_keys_containing=None):\n",
    "        log('evaluating on all metrics', priority=log_priority, indent=1)\n",
    "        evaluation_results = {}\n",
    "        for subject in self.all_subjects:\n",
    "            for eval_name in self.eval_names:\n",
    "                trial_ids = [trial_id for _subject, trial_id in self.subject_trials if _subject.subject_identifier == subject.subject_identifier]\n",
    "                for trial_id in trial_ids:\n",
    "                    splits = self.evaluation_datasets[(eval_name, subject.subject_identifier, trial_id)]\n",
    "                    auroc, accuracy = self._evaluate_on_metric_cv(model, bin_transformer, electrode_embeddings, subject, splits[0], splits[1], log_priority=log_priority+1, quick_eval=quick_eval)\n",
    "                    evaluation_results[(eval_name, subject.subject_identifier, trial_id)] = (auroc, accuracy)\n",
    "        \n",
    "        evaluation_results_strings = self._format_evaluation_results_strings(evaluation_results)\n",
    "        log('done evaluating on all metrics', priority=log_priority, indent=1)\n",
    "\n",
    "        if only_keys_containing is not None:\n",
    "            evaluation_results_strings = {k: v for k, v in evaluation_results_strings.items() if only_keys_containing in k}\n",
    "        return evaluation_results_strings\n",
    "\n",
    "    def _format_evaluation_results_strings(self, evaluation_results):\n",
    "        evaluation_results_strings = {}\n",
    "        for eval_name in self.eval_names:\n",
    "            auroc_values = []\n",
    "            acc_values = []\n",
    "            subject_aurocs = {}\n",
    "            subject_accs = {}\n",
    "            for (metric, subject_identifier, trial_id) in [key for key in evaluation_results.keys() if key[0] == eval_name]:\n",
    "                if subject_identifier not in subject_aurocs:\n",
    "                    subject_aurocs[subject_identifier] = []\n",
    "                    subject_accs[subject_identifier] = []\n",
    "                auroc, accuracy = evaluation_results[(eval_name, subject_identifier, trial_id)]\n",
    "                auroc, accuracy = auroc.item(), accuracy.item()\n",
    "\n",
    "                subject_aurocs[subject_identifier].append(auroc)\n",
    "                subject_accs[subject_identifier].append(accuracy)\n",
    "                evaluation_results_strings[f\"eval_auroc/{subject_identifier}_{trial_id}_{eval_name}\"] = auroc\n",
    "                evaluation_results_strings[f\"eval_acc/{subject_identifier}_{trial_id}_{eval_name}\"] = accuracy\n",
    "            for subject_identifier in subject_aurocs:\n",
    "                auroc_values.append(np.mean(subject_aurocs[subject_identifier]).item())\n",
    "                acc_values.append(np.mean(subject_accs[subject_identifier]).item())\n",
    "            if len(auroc_values) > 0:\n",
    "                evaluation_results_strings[f\"eval_auroc/average_{eval_name}\"] = np.mean(auroc_values).item()\n",
    "                evaluation_results_strings[f\"eval_acc/average_{eval_name}\"] = np.mean(acc_values).item()\n",
    "        return evaluation_results_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:22:25 gpu 16.4G ram 2.7G] Running evaluation on loaded model...\n",
      "[21:22:25 gpu 16.4G ram 2.7G]     evaluating on all metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/vast-storage/scratch/vast/yanglab/zaho/bfm_ic2/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/net/vast-storage/scratch/vast/yanglab/zaho/bfm_ic2/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/net/vast-storage/scratch/vast/yanglab/zaho/bfm_ic2/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:23:31 gpu 16.4G ram 2.8G]     done evaluating on all metrics\n",
      "{'eval_auroc/average_gpt2_surprisal': 0.5773692810457516, 'eval_auroc/average_volume': 0.6153839782666313, 'eval_auroc/average_speech': 0.9285877551020408}\n"
     ]
    }
   ],
   "source": [
    "eval_tasks = ['gpt2_surprisal', 'volume', 'speech']\n",
    "evaluation = FrozenModelEvaluation_SS_SM(\n",
    "    eval_tasks, eval_subject_trials, \n",
    "    training_config['data_dtype'], training_config['batch_size'],\n",
    "    electrode_embeddings.embeddings_map,\n",
    "    num_workers_eval=cluster_config['num_workers_eval'],\n",
    "    prefetch_factor=cluster_config['prefetch_factor'],\n",
    "    feature_aggregation_method=cluster_config['eval_aggregation_method'],\n",
    "    electrode_subset=eval_electrode_subset\n",
    ")\n",
    "\n",
    "# Run evaluation\n",
    "log(f\"Running evaluation on loaded model...\", priority=0)\n",
    "evaluation_results = evaluation.evaluate_on_all_metrics(\n",
    "    model, \n",
    "    bin_transformer, \n",
    "    electrode_embeddings, \n",
    "    log_priority=1, \n",
    "    quick_eval=cluster_config['quick_eval'], \n",
    "    only_keys_containing='auroc/average'\n",
    ")\n",
    "print(evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BFM IC2 (.venv)",
   "language": "python",
   "name": "bfm_ic2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
