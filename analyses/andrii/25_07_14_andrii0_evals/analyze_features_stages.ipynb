{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:26:27 gpu 0.1G ram 0.7G] Directory name: andrii0_lr0.003_wd0.0_dr0.1_rR1_t20250714_121055\n",
      "[22:26:27 gpu 0.1G ram 0.7G] Using device: cuda\n",
      "[22:26:27 gpu 0.1G ram 0.7G] Loading subjects...\n",
      "[22:26:27 gpu 0.1G ram 0.7G]     loading subject btbank4...\n",
      "[22:26:27 gpu 0.1G ram 0.7G]     loading subject btbank2...\n",
      "[22:26:27 gpu 0.1G ram 0.7G]     loading subject btbank7...\n",
      "[22:26:27 gpu 0.1G ram 0.7G]     loading subject btbank3...\n",
      "[22:26:27 gpu 0.1G ram 0.7G]     loading subject btbank1...\n",
      "[22:26:27 gpu 0.1G ram 0.7G]     loading subject btbank10...\n",
      "[22:26:27 gpu 0.1G ram 0.7G] Loading subject btbank1 trial 1\n",
      "[22:27:25 gpu 0.1G ram 5.9G] Loading subject btbank1 trial 2\n",
      "[22:28:09 gpu 0.1G ram 9.6G] Loading subject btbank2 trial 0\n",
      "[22:29:06 gpu 0.1G ram 14.5G] Loading subject btbank2 trial 4\n",
      "[22:30:28 gpu 0.1G ram 21.4G] Loading subject btbank3 trial 0\n",
      "[22:31:08 gpu 0.1G ram 24.6G] Loading subject btbank3 trial 1\n",
      "[22:32:09 gpu 0.1G ram 29.6G] Loading subject btbank4 trial 0\n",
      "[22:33:10 gpu 0.1G ram 34.4G] Loading subject btbank4 trial 1\n",
      "[22:34:12 gpu 0.1G ram 38.8G] Loading subject btbank7 trial 0\n",
      "[22:35:31 gpu 0.1G ram 44.3G] Loading subject btbank7 trial 1\n",
      "[22:37:01 gpu 0.1G ram 50.1G] Loading subject btbank10 trial 0\n",
      "[22:38:36 gpu 0.1G ram 54.6G] Loading subject btbank10 trial 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import wandb, os, json\n",
    "import time\n",
    "import numpy as np\n",
    "from torch.amp import autocast\n",
    "import gc\n",
    "\n",
    "from utils.muon_optimizer import Muon\n",
    "from subject.dataset import load_subjects\n",
    "from evaluation.neuroprobe_tasks import FrozenModelEvaluation_SS_SM\n",
    "from training_setup.training_config import log, update_dir_name, update_random_seed, parse_config_from_args, get_default_config, parse_subject_trials_from_config, convert_dtypes\n",
    "from torch.optim.lr_scheduler import ChainedScheduler\n",
    "from training_setup.training_config import convert_dtypes, unconvert_dtypes, parse_subject_trials_from_config\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from evaluation.neuroprobe.datasets import BrainTreebankSubjectTrialBenchmarkDataset\n",
    "import evaluation.neuroprobe.config as neuroprobe_config\n",
    "\n",
    "### PARSE MODEL DIR ###\n",
    "\n",
    "model_dir = \"andrii0_lr0.003_wd0.0_dr0.1_rR1_t20250714_121055\"\n",
    "batch_size = 100\n",
    "model_epoch = 0\n",
    "\n",
    "### LOAD CONFIG ###\n",
    "\n",
    "# Load the checkpoint\n",
    "if model_epoch < 0: model_epoch = \"final\"\n",
    "checkpoint_path = os.path.join(\"runs/data\", model_dir, f\"model_epoch_{model_epoch}.pth\")\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "config = unconvert_dtypes(checkpoint['config'])\n",
    "log(f\"Directory name: {model_dir}\", priority=0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "config['device'] = device\n",
    "log(f\"Using device: {device}\", priority=0)\n",
    "\n",
    "config['training']['train_subject_trials'] = []\n",
    "\n",
    "### LOAD SUBJECTS ###\n",
    "\n",
    "log(f\"Loading subjects...\", priority=0)\n",
    "# all_subjects is a dictionary of subjects, with the subject identifier as the key and the subject object as the value\n",
    "all_subjects = load_subjects(config['training']['train_subject_trials'], \n",
    "                             config['training']['eval_subject_trials'], config['training']['data_dtype'], \n",
    "                             cache=config['cluster']['cache_subjects'], allow_corrupted=False)\n",
    "for subject_identifier, trial_id in config['training']['eval_subject_trials']:\n",
    "    log(f\"Loading subject {subject_identifier} trial {trial_id}\", priority=0)\n",
    "    subject = all_subjects[subject_identifier]\n",
    "    subject.load_neural_data(trial_id)\n",
    "\n",
    "### LOAD MODEL ###\n",
    "\n",
    "# Import the training setup class dynamically based on config\n",
    "try:\n",
    "    setup_module = __import__(f'training_setup.{config[\"training\"][\"setup_name\"].lower()}', fromlist=[config[\"training\"][\"setup_name\"]])\n",
    "    setup_class = getattr(setup_module, config[\"training\"][\"setup_name\"])\n",
    "    training_setup = setup_class(all_subjects, config, verbose=True)\n",
    "except (ImportError, AttributeError) as e:\n",
    "    print(f\"Could not load training setup '{config['training']['setup_name']}'. Are you sure the filename and the class name are the same and correspond to the parameter? Error: {str(e)}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:44:13 gpu 0.1G ram 74.5G] Loading model...\n",
      "[22:44:25 gpu 0.1G ram 74.5G] Adding subject btbank4 to electrode embeddings...\n",
      "[22:44:25 gpu 0.1G ram 74.5G] Adding subject btbank2 to electrode embeddings...\n",
      "[22:44:25 gpu 0.1G ram 74.5G] Adding subject btbank7 to electrode embeddings...\n",
      "[22:44:25 gpu 0.1G ram 74.5G] Adding subject btbank3 to electrode embeddings...\n",
      "[22:44:25 gpu 0.1G ram 74.5G] Adding subject btbank1 to electrode embeddings...\n",
      "[22:44:25 gpu 0.1G ram 74.5G] Adding subject btbank10 to electrode embeddings...\n"
     ]
    }
   ],
   "source": [
    "log(f\"Loading model...\", priority=0)\n",
    "training_setup.initialize_model()\n",
    "\n",
    "log(f\"Loading the evaluation class...\", priority=0)\n",
    "evaluation = FrozenModelEvaluation_SS_SM(\n",
    "    # model evaluation function\n",
    "    model_preprocess_functions=training_setup.get_preprocess_functions(pretraining=False),\n",
    "    model_evaluation_function=training_setup.generate_frozen_features,\n",
    "    # benchmark parameters \n",
    "    eval_names=neuroprobe_config.NEUROPROBE_TASKS, lite=True,\n",
    "    subject_trials=[(all_subjects[subject_identifier], trial_id) for subject_identifier, trial_id in config['training']['eval_subject_trials']],\n",
    "    # dataloader parameters\n",
    "    device=device,\n",
    "    dtype=config['training']['data_dtype'],\n",
    "    batch_size=config['training']['batch_size'],\n",
    "    num_workers_eval=config['cluster']['num_workers_eval'],\n",
    "    prefetch_factor=config['cluster']['prefetch_factor'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Evaluating the epoch 0 model, while taking only the cls token for every timebin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:28:23 gpu 64.2G ram 76.2G] For subject btbank1 trial 1, generating features for 12402 indices\n",
      "[23:28:23 gpu 64.2G ram 76.1G]     Generating features for batch 0 of 12402\n",
      "[23:28:24 gpu 64.2G ram 76.2G]     Generating features for batch 400 of 12402\n",
      "[23:28:25 gpu 64.2G ram 76.2G]     Generating features for batch 800 of 12402\n",
      "[23:28:25 gpu 64.2G ram 76.2G]     Generating features for batch 1200 of 12402\n",
      "[23:28:26 gpu 64.2G ram 76.2G]     Generating features for batch 1600 of 12402\n",
      "[23:28:26 gpu 64.2G ram 76.2G]     Generating features for batch 2000 of 12402\n",
      "[23:28:27 gpu 64.2G ram 76.2G]     Generating features for batch 2400 of 12402\n",
      "[23:28:28 gpu 64.2G ram 76.2G]     Generating features for batch 2800 of 12402\n",
      "[23:28:28 gpu 64.2G ram 76.2G]     Generating features for batch 3200 of 12402\n",
      "[23:28:29 gpu 64.2G ram 76.2G]     Generating features for batch 3600 of 12402\n",
      "[23:28:29 gpu 64.2G ram 76.2G]     Generating features for batch 4000 of 12402\n",
      "[23:28:30 gpu 64.2G ram 76.2G]     Generating features for batch 4400 of 12402\n",
      "[23:28:31 gpu 64.2G ram 76.2G]     Generating features for batch 4800 of 12402\n",
      "[23:28:31 gpu 64.2G ram 76.2G]     Generating features for batch 5200 of 12402\n",
      "[23:28:32 gpu 64.2G ram 76.2G]     Generating features for batch 5600 of 12402\n",
      "[23:28:32 gpu 64.2G ram 76.2G]     Generating features for batch 6000 of 12402\n",
      "[23:28:33 gpu 64.2G ram 76.2G]     Generating features for batch 6400 of 12402\n",
      "[23:28:34 gpu 64.2G ram 76.2G]     Generating features for batch 6800 of 12402\n",
      "[23:28:34 gpu 64.2G ram 76.2G]     Generating features for batch 7200 of 12402\n",
      "[23:28:35 gpu 64.2G ram 76.2G]     Generating features for batch 7600 of 12402\n",
      "[23:28:35 gpu 64.2G ram 76.2G]     Generating features for batch 8000 of 12402\n",
      "[23:28:36 gpu 64.2G ram 76.2G]     Generating features for batch 8400 of 12402\n",
      "[23:28:37 gpu 64.2G ram 76.2G]     Generating features for batch 8800 of 12402\n",
      "[23:28:37 gpu 64.2G ram 76.2G]     Generating features for batch 9200 of 12402\n",
      "[23:28:38 gpu 64.2G ram 76.2G]     Generating features for batch 9600 of 12402\n",
      "[23:28:38 gpu 64.2G ram 76.2G]     Generating features for batch 10000 of 12402\n",
      "[23:28:39 gpu 64.2G ram 76.2G]     Generating features for batch 10400 of 12402\n",
      "[23:28:39 gpu 64.2G ram 76.2G]     Generating features for batch 10800 of 12402\n",
      "[23:28:40 gpu 64.2G ram 76.2G]     Generating features for batch 11200 of 12402\n",
      "[23:28:41 gpu 64.2G ram 76.2G]     Generating features for batch 11600 of 12402\n",
      "[23:28:41 gpu 64.2G ram 76.2G]     Generating features for batch 12000 of 12402\n",
      "[23:28:42 gpu 64.2G ram 76.2G]     Generating features for batch 12400 of 12402\n",
      "[23:28:57 gpu 64.2G ram 76.2G] For subject btbank1 trial 2, generating features for 10777 indices\n",
      "[23:28:57 gpu 64.2G ram 76.2G]     Generating features for batch 0 of 10777\n",
      "[23:28:58 gpu 64.2G ram 76.3G]     Generating features for batch 400 of 10777\n",
      "[23:28:58 gpu 64.2G ram 76.3G]     Generating features for batch 800 of 10777\n",
      "[23:28:59 gpu 64.2G ram 76.3G]     Generating features for batch 1200 of 10777\n",
      "[23:28:59 gpu 64.2G ram 76.3G]     Generating features for batch 1600 of 10777\n",
      "[23:29:00 gpu 64.2G ram 76.3G]     Generating features for batch 2000 of 10777\n",
      "[23:29:01 gpu 64.2G ram 76.3G]     Generating features for batch 2400 of 10777\n",
      "[23:29:01 gpu 64.2G ram 76.3G]     Generating features for batch 2800 of 10777\n",
      "[23:29:02 gpu 64.2G ram 76.3G]     Generating features for batch 3200 of 10777\n",
      "[23:29:02 gpu 64.2G ram 76.3G]     Generating features for batch 3600 of 10777\n",
      "[23:29:03 gpu 64.2G ram 76.3G]     Generating features for batch 4000 of 10777\n",
      "[23:29:04 gpu 64.2G ram 76.3G]     Generating features for batch 4400 of 10777\n",
      "[23:29:04 gpu 64.2G ram 76.3G]     Generating features for batch 4800 of 10777\n",
      "[23:29:05 gpu 64.2G ram 76.3G]     Generating features for batch 5200 of 10777\n",
      "[23:29:05 gpu 64.2G ram 76.3G]     Generating features for batch 5600 of 10777\n",
      "[23:29:06 gpu 64.2G ram 76.3G]     Generating features for batch 6000 of 10777\n",
      "[23:29:07 gpu 64.2G ram 76.3G]     Generating features for batch 6400 of 10777\n",
      "[23:29:07 gpu 64.2G ram 76.3G]     Generating features for batch 6800 of 10777\n",
      "[23:29:08 gpu 64.2G ram 76.3G]     Generating features for batch 7200 of 10777\n",
      "[23:29:08 gpu 64.2G ram 76.3G]     Generating features for batch 7600 of 10777\n",
      "[23:29:09 gpu 64.2G ram 76.3G]     Generating features for batch 8000 of 10777\n",
      "[23:29:09 gpu 64.2G ram 76.3G]     Generating features for batch 8400 of 10777\n",
      "[23:29:10 gpu 64.2G ram 76.3G]     Generating features for batch 8800 of 10777\n",
      "[23:29:11 gpu 64.2G ram 76.3G]     Generating features for batch 9200 of 10777\n",
      "[23:29:11 gpu 64.2G ram 76.3G]     Generating features for batch 9600 of 10777\n",
      "[23:29:12 gpu 64.2G ram 76.3G]     Generating features for batch 10000 of 10777\n",
      "[23:29:12 gpu 64.2G ram 76.3G]     Generating features for batch 10400 of 10777\n",
      "[23:29:27 gpu 64.2G ram 76.3G] For subject btbank2 trial 0, generating features for 9591 indices\n",
      "[23:29:27 gpu 64.2G ram 76.3G]     Generating features for batch 0 of 9591\n",
      "[23:29:27 gpu 64.2G ram 76.4G]     Generating features for batch 400 of 9591\n",
      "[23:29:28 gpu 64.2G ram 76.4G]     Generating features for batch 800 of 9591\n",
      "[23:29:28 gpu 64.2G ram 76.4G]     Generating features for batch 1200 of 9591\n",
      "[23:29:29 gpu 64.2G ram 76.4G]     Generating features for batch 1600 of 9591\n",
      "[23:29:29 gpu 64.2G ram 76.4G]     Generating features for batch 2000 of 9591\n",
      "[23:29:30 gpu 64.2G ram 76.4G]     Generating features for batch 2400 of 9591\n",
      "[23:29:31 gpu 64.2G ram 76.4G]     Generating features for batch 2800 of 9591\n",
      "[23:29:31 gpu 64.2G ram 76.4G]     Generating features for batch 3200 of 9591\n",
      "[23:29:32 gpu 64.2G ram 76.4G]     Generating features for batch 3600 of 9591\n",
      "[23:29:32 gpu 64.2G ram 76.4G]     Generating features for batch 4000 of 9591\n",
      "[23:29:33 gpu 64.2G ram 76.4G]     Generating features for batch 4400 of 9591\n",
      "[23:29:34 gpu 64.2G ram 76.4G]     Generating features for batch 4800 of 9591\n",
      "[23:29:34 gpu 64.2G ram 76.4G]     Generating features for batch 5200 of 9591\n",
      "[23:29:35 gpu 64.2G ram 76.4G]     Generating features for batch 5600 of 9591\n",
      "[23:29:35 gpu 64.2G ram 76.4G]     Generating features for batch 6000 of 9591\n",
      "[23:29:36 gpu 64.2G ram 76.4G]     Generating features for batch 6400 of 9591\n",
      "[23:29:37 gpu 64.2G ram 76.4G]     Generating features for batch 6800 of 9591\n",
      "[23:29:37 gpu 64.2G ram 76.4G]     Generating features for batch 7200 of 9591\n",
      "[23:29:38 gpu 64.2G ram 76.4G]     Generating features for batch 7600 of 9591\n",
      "[23:29:38 gpu 64.2G ram 76.4G]     Generating features for batch 8000 of 9591\n",
      "[23:29:39 gpu 64.2G ram 76.4G]     Generating features for batch 8400 of 9591\n",
      "[23:29:40 gpu 64.2G ram 76.4G]     Generating features for batch 8800 of 9591\n",
      "[23:29:40 gpu 64.2G ram 76.4G]     Generating features for batch 9200 of 9591\n",
      "[23:29:55 gpu 64.2G ram 76.4G] For subject btbank2 trial 4, generating features for 10663 indices\n",
      "[23:29:55 gpu 64.2G ram 76.4G]     Generating features for batch 0 of 10663\n",
      "[23:29:55 gpu 64.2G ram 76.6G]     Generating features for batch 400 of 10663\n",
      "[23:29:56 gpu 64.2G ram 76.6G]     Generating features for batch 800 of 10663\n",
      "[23:29:57 gpu 64.2G ram 76.6G]     Generating features for batch 1200 of 10663\n",
      "[23:29:57 gpu 64.2G ram 76.6G]     Generating features for batch 1600 of 10663\n",
      "[23:29:58 gpu 64.2G ram 76.6G]     Generating features for batch 2000 of 10663\n",
      "[23:29:58 gpu 64.2G ram 76.6G]     Generating features for batch 2400 of 10663\n",
      "[23:29:59 gpu 64.2G ram 76.6G]     Generating features for batch 2800 of 10663\n",
      "[23:30:00 gpu 64.2G ram 76.6G]     Generating features for batch 3200 of 10663\n",
      "[23:30:00 gpu 64.2G ram 76.6G]     Generating features for batch 3600 of 10663\n",
      "[23:30:01 gpu 64.2G ram 76.6G]     Generating features for batch 4000 of 10663\n",
      "[23:30:01 gpu 64.2G ram 76.6G]     Generating features for batch 4400 of 10663\n",
      "[23:30:02 gpu 64.2G ram 76.6G]     Generating features for batch 4800 of 10663\n",
      "[23:30:03 gpu 64.2G ram 76.6G]     Generating features for batch 5200 of 10663\n",
      "[23:30:03 gpu 64.2G ram 76.6G]     Generating features for batch 5600 of 10663\n",
      "[23:30:04 gpu 64.2G ram 76.6G]     Generating features for batch 6000 of 10663\n",
      "[23:30:04 gpu 64.2G ram 76.6G]     Generating features for batch 6400 of 10663\n",
      "[23:30:05 gpu 64.2G ram 76.6G]     Generating features for batch 6800 of 10663\n",
      "[23:30:06 gpu 64.2G ram 76.6G]     Generating features for batch 7200 of 10663\n",
      "[23:30:06 gpu 64.2G ram 76.6G]     Generating features for batch 7600 of 10663\n",
      "[23:30:07 gpu 64.2G ram 76.6G]     Generating features for batch 8000 of 10663\n",
      "[23:30:07 gpu 64.2G ram 76.6G]     Generating features for batch 8400 of 10663\n",
      "[23:30:08 gpu 64.2G ram 76.6G]     Generating features for batch 8800 of 10663\n",
      "[23:30:09 gpu 64.2G ram 76.6G]     Generating features for batch 9200 of 10663\n",
      "[23:30:09 gpu 64.2G ram 76.6G]     Generating features for batch 9600 of 10663\n",
      "[23:30:10 gpu 64.2G ram 76.6G]     Generating features for batch 10000 of 10663\n",
      "[23:30:11 gpu 64.2G ram 76.6G]     Generating features for batch 10400 of 10663\n",
      "[23:30:28 gpu 64.2G ram 76.6G] For subject btbank3 trial 0, generating features for 11738 indices\n",
      "[23:30:28 gpu 64.2G ram 76.6G]     Generating features for batch 0 of 11738\n",
      "[23:30:29 gpu 64.2G ram 76.7G]     Generating features for batch 400 of 11738\n",
      "[23:30:30 gpu 64.2G ram 76.7G]     Generating features for batch 800 of 11738\n",
      "[23:30:30 gpu 64.2G ram 76.7G]     Generating features for batch 1200 of 11738\n",
      "[23:30:31 gpu 64.2G ram 76.7G]     Generating features for batch 1600 of 11738\n",
      "[23:30:31 gpu 64.2G ram 76.7G]     Generating features for batch 2000 of 11738\n",
      "[23:30:32 gpu 64.2G ram 76.7G]     Generating features for batch 2400 of 11738\n",
      "[23:30:32 gpu 64.2G ram 76.7G]     Generating features for batch 2800 of 11738\n",
      "[23:30:33 gpu 64.2G ram 76.7G]     Generating features for batch 3200 of 11738\n",
      "[23:30:33 gpu 64.2G ram 76.7G]     Generating features for batch 3600 of 11738\n",
      "[23:30:34 gpu 64.2G ram 76.7G]     Generating features for batch 4000 of 11738\n",
      "[23:30:35 gpu 64.2G ram 76.7G]     Generating features for batch 4400 of 11738\n",
      "[23:30:35 gpu 64.2G ram 76.7G]     Generating features for batch 4800 of 11738\n",
      "[23:30:36 gpu 64.2G ram 76.7G]     Generating features for batch 5200 of 11738\n",
      "[23:30:36 gpu 64.2G ram 76.7G]     Generating features for batch 5600 of 11738\n",
      "[23:30:37 gpu 64.2G ram 76.7G]     Generating features for batch 6000 of 11738\n",
      "[23:30:37 gpu 64.2G ram 76.7G]     Generating features for batch 6400 of 11738\n",
      "[23:30:38 gpu 64.2G ram 76.7G]     Generating features for batch 6800 of 11738\n",
      "[23:30:38 gpu 64.2G ram 76.7G]     Generating features for batch 7200 of 11738\n",
      "[23:30:39 gpu 64.2G ram 76.7G]     Generating features for batch 7600 of 11738\n",
      "[23:30:40 gpu 64.2G ram 76.7G]     Generating features for batch 8000 of 11738\n",
      "[23:30:40 gpu 64.2G ram 76.7G]     Generating features for batch 8400 of 11738\n",
      "[23:30:41 gpu 64.2G ram 76.7G]     Generating features for batch 8800 of 11738\n",
      "[23:30:41 gpu 64.2G ram 76.7G]     Generating features for batch 9200 of 11738\n",
      "[23:30:42 gpu 64.2G ram 76.7G]     Generating features for batch 9600 of 11738\n",
      "[23:30:42 gpu 64.2G ram 76.7G]     Generating features for batch 10000 of 11738\n",
      "[23:30:43 gpu 64.2G ram 76.7G]     Generating features for batch 10400 of 11738\n",
      "[23:30:44 gpu 64.2G ram 76.7G]     Generating features for batch 10800 of 11738\n",
      "[23:30:44 gpu 64.2G ram 76.7G]     Generating features for batch 11200 of 11738\n",
      "[23:30:45 gpu 64.2G ram 76.7G]     Generating features for batch 11600 of 11738\n",
      "[23:31:00 gpu 64.2G ram 76.7G] For subject btbank3 trial 1, generating features for 10119 indices\n",
      "[23:31:00 gpu 64.2G ram 76.7G]     Generating features for batch 0 of 10119\n",
      "[23:31:01 gpu 64.2G ram 76.8G]     Generating features for batch 400 of 10119\n",
      "[23:31:01 gpu 64.2G ram 76.8G]     Generating features for batch 800 of 10119\n",
      "[23:31:02 gpu 64.2G ram 76.8G]     Generating features for batch 1200 of 10119\n",
      "[23:31:03 gpu 64.2G ram 76.8G]     Generating features for batch 1600 of 10119\n",
      "[23:31:03 gpu 64.2G ram 76.8G]     Generating features for batch 2000 of 10119\n",
      "[23:31:04 gpu 64.2G ram 76.8G]     Generating features for batch 2400 of 10119\n",
      "[23:31:04 gpu 64.2G ram 76.8G]     Generating features for batch 2800 of 10119\n",
      "[23:31:05 gpu 64.2G ram 76.8G]     Generating features for batch 3200 of 10119\n",
      "[23:31:05 gpu 64.2G ram 76.8G]     Generating features for batch 3600 of 10119\n",
      "[23:31:06 gpu 64.2G ram 76.8G]     Generating features for batch 4000 of 10119\n",
      "[23:31:07 gpu 64.2G ram 76.8G]     Generating features for batch 4400 of 10119\n",
      "[23:31:07 gpu 64.2G ram 76.8G]     Generating features for batch 4800 of 10119\n",
      "[23:31:08 gpu 64.2G ram 76.8G]     Generating features for batch 5200 of 10119\n",
      "[23:31:08 gpu 64.2G ram 76.8G]     Generating features for batch 5600 of 10119\n",
      "[23:31:09 gpu 64.2G ram 76.8G]     Generating features for batch 6000 of 10119\n",
      "[23:31:09 gpu 64.2G ram 76.8G]     Generating features for batch 6400 of 10119\n",
      "[23:31:10 gpu 64.2G ram 76.8G]     Generating features for batch 6800 of 10119\n",
      "[23:31:10 gpu 64.2G ram 76.8G]     Generating features for batch 7200 of 10119\n",
      "[23:31:11 gpu 64.2G ram 76.8G]     Generating features for batch 7600 of 10119\n",
      "[23:31:12 gpu 64.2G ram 76.8G]     Generating features for batch 8000 of 10119\n",
      "[23:31:12 gpu 64.2G ram 76.8G]     Generating features for batch 8400 of 10119\n",
      "[23:31:13 gpu 64.2G ram 76.8G]     Generating features for batch 8800 of 10119\n",
      "[23:31:13 gpu 64.2G ram 76.8G]     Generating features for batch 9200 of 10119\n",
      "[23:31:14 gpu 64.2G ram 76.8G]     Generating features for batch 9600 of 10119\n",
      "[23:31:14 gpu 64.2G ram 76.8G]     Generating features for batch 10000 of 10119\n",
      "[23:31:27 gpu 64.2G ram 76.8G] For subject btbank4 trial 0, generating features for 9031 indices\n",
      "[23:31:27 gpu 64.2G ram 76.8G]     Generating features for batch 0 of 9031\n",
      "[23:31:28 gpu 64.2G ram 77.0G]     Generating features for batch 400 of 9031\n",
      "[23:31:29 gpu 64.2G ram 77.0G]     Generating features for batch 800 of 9031\n",
      "[23:31:29 gpu 64.2G ram 77.0G]     Generating features for batch 1200 of 9031\n",
      "[23:31:30 gpu 64.2G ram 77.0G]     Generating features for batch 1600 of 9031\n",
      "[23:31:30 gpu 64.2G ram 77.0G]     Generating features for batch 2000 of 9031\n",
      "[23:31:31 gpu 64.2G ram 77.0G]     Generating features for batch 2400 of 9031\n",
      "[23:31:32 gpu 64.2G ram 77.0G]     Generating features for batch 2800 of 9031\n",
      "[23:31:32 gpu 64.2G ram 77.0G]     Generating features for batch 3200 of 9031\n",
      "[23:31:33 gpu 64.2G ram 77.0G]     Generating features for batch 3600 of 9031\n",
      "[23:31:33 gpu 64.2G ram 77.0G]     Generating features for batch 4000 of 9031\n",
      "[23:31:34 gpu 64.2G ram 77.0G]     Generating features for batch 4400 of 9031\n",
      "[23:31:35 gpu 64.2G ram 77.0G]     Generating features for batch 4800 of 9031\n",
      "[23:31:35 gpu 64.2G ram 77.0G]     Generating features for batch 5200 of 9031\n",
      "[23:31:36 gpu 64.2G ram 77.0G]     Generating features for batch 5600 of 9031\n",
      "[23:31:36 gpu 64.2G ram 77.0G]     Generating features for batch 6000 of 9031\n",
      "[23:31:37 gpu 64.2G ram 77.0G]     Generating features for batch 6400 of 9031\n",
      "[23:31:38 gpu 64.2G ram 77.0G]     Generating features for batch 6800 of 9031\n",
      "[23:31:38 gpu 64.2G ram 77.0G]     Generating features for batch 7200 of 9031\n",
      "[23:31:39 gpu 64.2G ram 77.0G]     Generating features for batch 7600 of 9031\n",
      "[23:31:39 gpu 64.2G ram 77.0G]     Generating features for batch 8000 of 9031\n",
      "[23:31:40 gpu 64.2G ram 77.0G]     Generating features for batch 8400 of 9031\n",
      "[23:31:41 gpu 64.2G ram 77.0G]     Generating features for batch 8800 of 9031\n",
      "[23:32:56 gpu 64.2G ram 77.0G] For subject btbank4 trial 1, generating features for 9958 indices\n",
      "[23:32:56 gpu 64.2G ram 77.0G]     Generating features for batch 0 of 9958\n",
      "[23:32:57 gpu 64.2G ram 77.1G]     Generating features for batch 400 of 9958\n",
      "[23:32:58 gpu 64.2G ram 77.1G]     Generating features for batch 800 of 9958\n",
      "[23:32:58 gpu 64.2G ram 77.1G]     Generating features for batch 1200 of 9958\n",
      "[23:32:59 gpu 64.2G ram 77.1G]     Generating features for batch 1600 of 9958\n",
      "[23:32:59 gpu 64.2G ram 77.1G]     Generating features for batch 2000 of 9958\n",
      "[23:33:00 gpu 64.2G ram 77.1G]     Generating features for batch 2400 of 9958\n",
      "[23:33:01 gpu 64.2G ram 77.1G]     Generating features for batch 2800 of 9958\n",
      "[23:33:01 gpu 64.2G ram 77.1G]     Generating features for batch 3200 of 9958\n",
      "[23:33:02 gpu 64.2G ram 77.1G]     Generating features for batch 3600 of 9958\n",
      "[23:33:02 gpu 64.2G ram 77.1G]     Generating features for batch 4000 of 9958\n",
      "[23:33:03 gpu 64.2G ram 77.1G]     Generating features for batch 4400 of 9958\n",
      "[23:33:04 gpu 64.2G ram 77.1G]     Generating features for batch 4800 of 9958\n",
      "[23:33:04 gpu 64.2G ram 77.1G]     Generating features for batch 5200 of 9958\n",
      "[23:33:05 gpu 64.2G ram 77.1G]     Generating features for batch 5600 of 9958\n",
      "[23:33:06 gpu 64.2G ram 77.1G]     Generating features for batch 6000 of 9958\n",
      "[23:33:06 gpu 64.2G ram 77.1G]     Generating features for batch 6400 of 9958\n",
      "[23:33:07 gpu 64.2G ram 77.1G]     Generating features for batch 6800 of 9958\n",
      "[23:33:07 gpu 64.2G ram 77.1G]     Generating features for batch 7200 of 9958\n",
      "[23:33:08 gpu 64.2G ram 77.1G]     Generating features for batch 7600 of 9958\n",
      "[23:33:09 gpu 64.2G ram 77.1G]     Generating features for batch 8000 of 9958\n",
      "[23:33:09 gpu 64.2G ram 77.1G]     Generating features for batch 8400 of 9958\n",
      "[23:33:10 gpu 64.2G ram 77.1G]     Generating features for batch 8800 of 9958\n",
      "[23:33:11 gpu 64.2G ram 77.1G]     Generating features for batch 9200 of 9958\n",
      "[23:33:11 gpu 64.2G ram 77.1G]     Generating features for batch 9600 of 9958\n",
      "[23:33:29 gpu 64.2G ram 77.1G] For subject btbank7 trial 0, generating features for 11499 indices\n",
      "[23:33:29 gpu 64.2G ram 77.1G]     Generating features for batch 0 of 11499\n",
      "[23:33:30 gpu 64.2G ram 77.2G]     Generating features for batch 400 of 11499\n",
      "[23:33:30 gpu 64.2G ram 77.2G]     Generating features for batch 800 of 11499\n",
      "[23:33:31 gpu 64.2G ram 77.2G]     Generating features for batch 1200 of 11499\n",
      "[23:33:32 gpu 64.2G ram 77.2G]     Generating features for batch 1600 of 11499\n",
      "[23:33:32 gpu 64.2G ram 77.2G]     Generating features for batch 2000 of 11499\n",
      "[23:33:33 gpu 64.2G ram 77.2G]     Generating features for batch 2400 of 11499\n",
      "[23:33:34 gpu 64.2G ram 77.2G]     Generating features for batch 2800 of 11499\n",
      "[23:33:34 gpu 64.2G ram 77.2G]     Generating features for batch 3200 of 11499\n",
      "[23:33:35 gpu 64.2G ram 77.2G]     Generating features for batch 3600 of 11499\n",
      "[23:33:36 gpu 64.2G ram 77.2G]     Generating features for batch 4000 of 11499\n",
      "[23:33:36 gpu 64.2G ram 77.2G]     Generating features for batch 4400 of 11499\n",
      "[23:33:37 gpu 64.2G ram 77.2G]     Generating features for batch 4800 of 11499\n",
      "[23:33:37 gpu 64.2G ram 77.2G]     Generating features for batch 5200 of 11499\n",
      "[23:33:38 gpu 64.2G ram 77.2G]     Generating features for batch 5600 of 11499\n",
      "[23:33:39 gpu 64.2G ram 77.2G]     Generating features for batch 6000 of 11499\n",
      "[23:33:39 gpu 64.2G ram 77.2G]     Generating features for batch 6400 of 11499\n",
      "[23:33:40 gpu 64.2G ram 77.2G]     Generating features for batch 6800 of 11499\n",
      "[23:33:41 gpu 64.2G ram 77.2G]     Generating features for batch 7200 of 11499\n",
      "[23:33:41 gpu 64.2G ram 77.2G]     Generating features for batch 7600 of 11499\n",
      "[23:33:42 gpu 64.2G ram 77.2G]     Generating features for batch 8000 of 11499\n",
      "[23:33:42 gpu 64.2G ram 77.2G]     Generating features for batch 8400 of 11499\n",
      "[23:33:43 gpu 64.2G ram 77.2G]     Generating features for batch 8800 of 11499\n",
      "[23:33:44 gpu 64.2G ram 77.2G]     Generating features for batch 9200 of 11499\n",
      "[23:33:44 gpu 64.2G ram 77.2G]     Generating features for batch 9600 of 11499\n",
      "[23:33:45 gpu 64.2G ram 77.2G]     Generating features for batch 10000 of 11499\n",
      "[23:33:46 gpu 64.2G ram 77.2G]     Generating features for batch 10400 of 11499\n",
      "[23:33:46 gpu 64.2G ram 77.2G]     Generating features for batch 10800 of 11499\n",
      "[23:33:47 gpu 64.2G ram 77.2G]     Generating features for batch 11200 of 11499\n",
      "[23:34:02 gpu 64.2G ram 77.2G] For subject btbank7 trial 1, generating features for 9629 indices\n",
      "[23:34:02 gpu 64.2G ram 77.2G]     Generating features for batch 0 of 9629\n",
      "[23:34:03 gpu 64.2G ram 77.3G]     Generating features for batch 400 of 9629\n",
      "[23:34:03 gpu 64.2G ram 77.3G]     Generating features for batch 800 of 9629\n",
      "[23:34:04 gpu 64.2G ram 77.3G]     Generating features for batch 1200 of 9629\n",
      "[23:34:05 gpu 64.2G ram 77.3G]     Generating features for batch 1600 of 9629\n",
      "[23:34:05 gpu 64.2G ram 77.3G]     Generating features for batch 2000 of 9629\n",
      "[23:34:06 gpu 64.2G ram 77.3G]     Generating features for batch 2400 of 9629\n",
      "[23:34:07 gpu 64.2G ram 77.3G]     Generating features for batch 2800 of 9629\n",
      "[23:34:07 gpu 64.2G ram 77.3G]     Generating features for batch 3200 of 9629\n",
      "[23:34:08 gpu 64.2G ram 77.3G]     Generating features for batch 3600 of 9629\n",
      "[23:34:09 gpu 64.2G ram 77.3G]     Generating features for batch 4000 of 9629\n",
      "[23:34:09 gpu 64.2G ram 77.3G]     Generating features for batch 4400 of 9629\n",
      "[23:34:10 gpu 64.2G ram 77.3G]     Generating features for batch 4800 of 9629\n",
      "[23:34:10 gpu 64.2G ram 77.3G]     Generating features for batch 5200 of 9629\n",
      "[23:34:11 gpu 64.2G ram 77.3G]     Generating features for batch 5600 of 9629\n",
      "[23:34:12 gpu 64.2G ram 77.3G]     Generating features for batch 6000 of 9629\n",
      "[23:34:12 gpu 64.2G ram 77.3G]     Generating features for batch 6400 of 9629\n",
      "[23:34:13 gpu 64.2G ram 77.3G]     Generating features for batch 6800 of 9629\n",
      "[23:34:14 gpu 64.2G ram 77.3G]     Generating features for batch 7200 of 9629\n",
      "[23:34:14 gpu 64.2G ram 77.3G]     Generating features for batch 7600 of 9629\n",
      "[23:34:15 gpu 64.2G ram 77.3G]     Generating features for batch 8000 of 9629\n",
      "[23:34:15 gpu 64.2G ram 77.3G]     Generating features for batch 8400 of 9629\n",
      "[23:34:16 gpu 64.2G ram 77.3G]     Generating features for batch 8800 of 9629\n",
      "[23:34:17 gpu 64.2G ram 77.3G]     Generating features for batch 9200 of 9629\n",
      "[23:34:17 gpu 64.2G ram 77.3G]     Generating features for batch 9600 of 9629\n",
      "[23:34:34 gpu 64.2G ram 77.3G] For subject btbank10 trial 0, generating features for 10799 indices\n",
      "[23:34:34 gpu 64.2G ram 77.3G]     Generating features for batch 0 of 10799\n",
      "[23:34:35 gpu 64.2G ram 77.5G]     Generating features for batch 400 of 10799\n",
      "[23:34:35 gpu 64.2G ram 77.5G]     Generating features for batch 800 of 10799\n",
      "[23:34:36 gpu 64.2G ram 77.5G]     Generating features for batch 1200 of 10799\n",
      "[23:34:37 gpu 64.2G ram 77.5G]     Generating features for batch 1600 of 10799\n",
      "[23:34:37 gpu 64.2G ram 77.5G]     Generating features for batch 2000 of 10799\n",
      "[23:34:38 gpu 64.2G ram 77.5G]     Generating features for batch 2400 of 10799\n",
      "[23:34:39 gpu 64.2G ram 77.5G]     Generating features for batch 2800 of 10799\n",
      "[23:34:39 gpu 64.2G ram 77.5G]     Generating features for batch 3200 of 10799\n",
      "[23:34:40 gpu 64.2G ram 77.5G]     Generating features for batch 3600 of 10799\n",
      "[23:34:41 gpu 64.2G ram 77.5G]     Generating features for batch 4000 of 10799\n",
      "[23:34:41 gpu 64.2G ram 77.5G]     Generating features for batch 4400 of 10799\n",
      "[23:34:42 gpu 64.2G ram 77.5G]     Generating features for batch 4800 of 10799\n",
      "[23:34:43 gpu 64.2G ram 77.5G]     Generating features for batch 5200 of 10799\n",
      "[23:34:43 gpu 64.2G ram 77.5G]     Generating features for batch 5600 of 10799\n",
      "[23:34:44 gpu 64.2G ram 77.5G]     Generating features for batch 6000 of 10799\n",
      "[23:34:44 gpu 64.2G ram 77.5G]     Generating features for batch 6400 of 10799\n",
      "[23:34:45 gpu 64.2G ram 77.5G]     Generating features for batch 6800 of 10799\n",
      "[23:34:46 gpu 64.2G ram 77.5G]     Generating features for batch 7200 of 10799\n",
      "[23:34:46 gpu 64.2G ram 77.5G]     Generating features for batch 7600 of 10799\n",
      "[23:34:47 gpu 64.2G ram 77.5G]     Generating features for batch 8000 of 10799\n",
      "[23:34:48 gpu 64.2G ram 77.5G]     Generating features for batch 8400 of 10799\n",
      "[23:34:48 gpu 64.2G ram 77.5G]     Generating features for batch 8800 of 10799\n",
      "[23:34:49 gpu 64.2G ram 77.5G]     Generating features for batch 9200 of 10799\n",
      "[23:34:50 gpu 64.2G ram 77.5G]     Generating features for batch 9600 of 10799\n",
      "[23:34:50 gpu 64.2G ram 77.5G]     Generating features for batch 10000 of 10799\n",
      "[23:34:51 gpu 64.2G ram 77.5G]     Generating features for batch 10400 of 10799\n",
      "[23:35:10 gpu 64.2G ram 77.5G] For subject btbank10 trial 1, generating features for 12722 indices\n",
      "[23:35:10 gpu 64.2G ram 77.5G]     Generating features for batch 0 of 12722\n",
      "[23:35:10 gpu 64.2G ram 77.6G]     Generating features for batch 400 of 12722\n",
      "[23:35:11 gpu 64.2G ram 77.6G]     Generating features for batch 800 of 12722\n",
      "[23:35:12 gpu 64.2G ram 77.6G]     Generating features for batch 1200 of 12722\n",
      "[23:35:12 gpu 64.2G ram 77.6G]     Generating features for batch 1600 of 12722\n",
      "[23:35:13 gpu 64.2G ram 77.6G]     Generating features for batch 2000 of 12722\n",
      "[23:35:13 gpu 64.2G ram 77.6G]     Generating features for batch 2400 of 12722\n",
      "[23:35:14 gpu 64.2G ram 77.6G]     Generating features for batch 2800 of 12722\n",
      "[23:35:15 gpu 64.2G ram 77.6G]     Generating features for batch 3200 of 12722\n",
      "[23:35:15 gpu 64.2G ram 77.6G]     Generating features for batch 3600 of 12722\n",
      "[23:35:16 gpu 64.2G ram 77.6G]     Generating features for batch 4000 of 12722\n",
      "[23:35:17 gpu 64.2G ram 77.6G]     Generating features for batch 4400 of 12722\n",
      "[23:35:17 gpu 64.2G ram 77.6G]     Generating features for batch 4800 of 12722\n",
      "[23:35:18 gpu 64.2G ram 77.6G]     Generating features for batch 5200 of 12722\n",
      "[23:35:19 gpu 64.2G ram 77.6G]     Generating features for batch 5600 of 12722\n",
      "[23:35:19 gpu 64.2G ram 77.6G]     Generating features for batch 6000 of 12722\n",
      "[23:35:20 gpu 64.2G ram 77.6G]     Generating features for batch 6400 of 12722\n",
      "[23:35:20 gpu 64.2G ram 77.6G]     Generating features for batch 6800 of 12722\n",
      "[23:35:21 gpu 64.2G ram 77.6G]     Generating features for batch 7200 of 12722\n",
      "[23:35:22 gpu 64.2G ram 77.6G]     Generating features for batch 7600 of 12722\n",
      "[23:35:22 gpu 64.2G ram 77.6G]     Generating features for batch 8000 of 12722\n",
      "[23:35:23 gpu 64.2G ram 77.6G]     Generating features for batch 8400 of 12722\n",
      "[23:35:24 gpu 64.2G ram 77.6G]     Generating features for batch 8800 of 12722\n",
      "[23:35:24 gpu 64.2G ram 77.6G]     Generating features for batch 9200 of 12722\n",
      "[23:35:25 gpu 64.2G ram 77.6G]     Generating features for batch 9600 of 12722\n",
      "[23:35:26 gpu 64.2G ram 77.6G]     Generating features for batch 10000 of 12722\n",
      "[23:35:26 gpu 64.2G ram 77.6G]     Generating features for batch 10400 of 12722\n",
      "[23:35:27 gpu 64.2G ram 77.6G]     Generating features for batch 10800 of 12722\n",
      "[23:35:28 gpu 64.2G ram 77.6G]     Generating features for batch 11200 of 12722\n",
      "[23:35:28 gpu 64.2G ram 77.6G]     Generating features for batch 11600 of 12722\n",
      "[23:35:29 gpu 64.2G ram 77.6G]     Generating features for batch 12000 of 12722\n",
      "[23:35:29 gpu 64.2G ram 77.6G]     Generating features for batch 12400 of 12722\n"
     ]
    }
   ],
   "source": [
    "from evaluation.neuroprobe.datasets import BrainTreebankSubjectTrialBenchmarkDataset\n",
    "\n",
    "def generate_frozen_features(batch):\n",
    "    # INPUT:\n",
    "    #   batch['data'] shape: (batch_size, n_electrodes, n_timesamples)\n",
    "    #   batch['electrode_labels'] shape: list of length 1 (since it's the same across the batch), each element is a list of electrode labels\n",
    "    #   batch['metadata']: dictionary containing metadata like the subject identifier and trial id, sampling rate, etc.\n",
    "    # OUTPUT:\n",
    "    #   features shape: (batch_size, *) where * can be arbitrary (and will be concatenated for regression)\n",
    "    self = training_setup\n",
    "\n",
    "    batch['data'] = batch['data'].to(self.model.device, dtype=self.model.dtype, non_blocking=True)\n",
    "    batch['electrode_index'] = batch['electrode_index'].to(self.model.device, non_blocking=True)\n",
    "\n",
    "    embeddings = self.electrode_embeddings(batch)\n",
    "    features = self.model(batch, embeddings, electrode_transformer_only=True) # shape: (batch_size, n_electrodes + 1, n_timebins, d_model)\n",
    "    features = features[:, 0:1, :, :] # shape: (batch_size, 1, n_timebins, d_model) -- take just the cls token\n",
    "\n",
    "    if self.config['cluster']['eval_aggregation_method'] == 'mean':\n",
    "        features = features.mean(dim=[1, 2])\n",
    "    elif self.config['cluster']['eval_aggregation_method'] == 'concat':\n",
    "        features = features.reshape(batch['data'].shape[0], -1)\n",
    "    return features\n",
    "\n",
    "precomputed_features = {}\n",
    "\n",
    "window_size = 2048 # sampling rate\n",
    "batch_size = 400\n",
    "for subject_identifier, trial_id in config['training']['eval_subject_trials']:\n",
    "    subject = all_subjects[subject_identifier]\n",
    "    electrode_subset_indices = [subject.electrode_labels.index(e) for e in neuroprobe_config.NEUROPROBE_LITE_ELECTRODES[subject_identifier]]\n",
    "    \n",
    "    indices = []\n",
    "    for eval_name in neuroprobe_config.NEUROPROBE_TASKS:\n",
    "        dataset = BrainTreebankSubjectTrialBenchmarkDataset(subject, trial_id, torch.float32, eval_name, output_indices=True)\n",
    "\n",
    "        for i, ((index_start, index_end), label) in enumerate(dataset):\n",
    "            indices.append(index_start)\n",
    "    indices = torch.tensor(sorted(list(set(indices))))\n",
    "\n",
    "    log(f\"For subject {subject_identifier} trial {trial_id}, generating features for {len(indices)} indices\", priority=0)\n",
    "\n",
    "    frozen_features = None\n",
    "    for i_start in range(0, len(indices), batch_size):\n",
    "        log(f\"Generating features for batch {i_start} of {len(indices)}\", priority=0, indent=1)\n",
    "        i_end = min(i_start + batch_size, len(indices))\n",
    "        indices_batch = indices[i_start:i_end]\n",
    "\n",
    "        model_input = torch.zeros((len(indices_batch), len(electrode_subset_indices), window_size))\n",
    "        for i_index, index in enumerate(indices_batch):\n",
    "            model_input[i_index, :, :] = subject.get_all_electrode_data(trial_id, window_from=index, window_to=index+window_size)[electrode_subset_indices, :]\n",
    "        model_input = model_input.to(device)\n",
    "\n",
    "        batch = {\n",
    "            'data': model_input, # shape (batch_size, n_electrodes, n_samples),\n",
    "            'electrode_labels': [neuroprobe_config.NEUROPROBE_LITE_ELECTRODES[subject_identifier]],\n",
    "            'metadata': {\n",
    "                'subject_identifier': subject_identifier,\n",
    "                'trial_id': trial_id,\n",
    "                'sampling_rate': subject.get_sampling_rate(trial_id),\n",
    "            },\n",
    "        }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for preprocess_function in training_setup.get_preprocess_functions(pretraining=False):\n",
    "                batch = preprocess_function(batch)\n",
    "            features = generate_frozen_features(batch).reshape(batch['data'].shape[0], -1)\n",
    "        if frozen_features is None:\n",
    "            frozen_features = torch.zeros((len(indices), features.shape[1]))\n",
    "        frozen_features[i_start:i_end, :] = features\n",
    "\n",
    "    precomputed_features[subject_identifier, trial_id] = {\n",
    "        'frozen_features': frozen_features,\n",
    "        'indices': indices,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([ 415356,  571056,  419781,  617368,  425242,  717870,  428396,  721966,\n",
      "         454743,  728110,  455782,  780557,  458240,  782605,  460618,  786701,\n",
      "         464098,  796941,  467916,  800013,  472051,  801037,  480328,  805133,\n",
      "         487390,  810253,  502320,  812301,  503375,  814349,  513045, 1141436,\n",
      "         520173, 1158434,  524042, 1161506,  528330, 1165602,  533802, 1168674,\n",
      "         536450, 1170722,  542348, 1219105,  543830, 1222177,  544837, 1223201,\n",
      "         550429, 1224225,  555844, 1231393,  558581, 1236513,  563006, 1238561,\n",
      "         580396, 1239585,  585911, 1241633,  591654, 1242657,  593740, 1244705,\n",
      "         596232, 1250849,  599408, 1254945,  604011, 1263137,  609837, 1274401,\n",
      "         626304, 1276449,  632737, 1399075,  639207, 1407267,  647410, 1414435,\n",
      "         649992, 1419555,  660042, 1422627,  663058, 1427747,  668447, 1430819,\n",
      "         673047, 1431843,  676225, 1435939,  679812, 1450275,  683175, 1478850,\n",
      "         688834, 1480898,  695106, 1483970]), tensor([ 417404,  573104,  421829,  619416,  427290,  719918,  430444,  724014,\n",
      "         456791,  730158,  457830,  782605,  460288,  784653,  462666,  788749,\n",
      "         466146,  798989,  469964,  802061,  474099,  803085,  482376,  807181,\n",
      "         489438,  812301,  504368,  814349,  505423,  816397,  515093, 1143484,\n",
      "         522221, 1160482,  526090, 1163554,  530378, 1167650,  535850, 1170722,\n",
      "         538498, 1172770,  544396, 1221153,  545878, 1224225,  546885, 1225249,\n",
      "         552477, 1226273,  557892, 1233441,  560629, 1238561,  565054, 1240609,\n",
      "         582444, 1241633,  587959, 1243681,  593702, 1244705,  595788, 1246753,\n",
      "         598280, 1252897,  601456, 1256993,  606059, 1265185,  611885, 1276449,\n",
      "         628352, 1278497,  634785, 1401123,  641255, 1409315,  649458, 1416483,\n",
      "         652040, 1421603,  662090, 1424675,  665106, 1429795,  670495, 1432867,\n",
      "         675095, 1433891,  678273, 1437987,  681860, 1452323,  685223, 1480898,\n",
      "         690882, 1482946,  697154, 1486018])]\n"
     ]
    }
   ],
   "source": [
    "from evaluation.neuroprobe.datasets import BrainTreebankSubjectTrialBenchmarkDataset\n",
    "\n",
    "subject_identifier = \"btbank1\"\n",
    "trial_id = 1\n",
    "subject = all_subjects[subject_identifier]\n",
    "\n",
    "dataset = BrainTreebankSubjectTrialBenchmarkDataset(subject, trial_id, torch.float32, \"onset\", output_indices=True)\n",
    "dataloader = DataLoader(dataset, batch_size=100, shuffle=False, num_workers=1, prefetch_factor=1)\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(batch[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/vast-storage/scratch/vast/yanglab/zaho/bfm_ic2/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([119, 2048])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m evaluation\u001b[38;5;241m.\u001b[39mmodel_preprocess_functions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     19\u001b[0m evaluation\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m400\u001b[39m\n\u001b[0;32m---> 21\u001b[0m epoch0_eval_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_on_all_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_priority\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquick_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/net/vast-storage/scratch/vast/yanglab/zaho/bfm/evaluation/neuroprobe_tasks.py:181\u001b[0m, in \u001b[0;36mFrozenModelEvaluation_SS_SM.evaluate_on_all_metrics\u001b[0;34m(self, log_priority, quick_eval, key_prefix, only_keys_containing, raw_data)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m trial_id \u001b[38;5;129;01min\u001b[39;00m trial_ids:\n\u001b[1;32m    180\u001b[0m             splits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_datasets[(eval_name, subject\u001b[38;5;241m.\u001b[39msubject_identifier, trial_id)]\n\u001b[0;32m--> 181\u001b[0m             auroc, accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_on_metric_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_priority\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_priority\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquick_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquick_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m             evaluation_results[(eval_name, subject\u001b[38;5;241m.\u001b[39msubject_identifier, trial_id)] \u001b[38;5;241m=\u001b[39m (auroc, accuracy)\n\u001b[1;32m    184\u001b[0m evaluation_results_strings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_evaluation_results_strings(evaluation_results)\n",
      "File \u001b[0;32m/net/vast-storage/scratch/vast/yanglab/zaho/bfm/evaluation/neuroprobe_tasks.py:167\u001b[0m, in \u001b[0;36mFrozenModelEvaluation_SS_SM._evaluate_on_metric_cv\u001b[0;34m(self, subject, trial_id, train_datasets, test_datasets, log_priority, quick_eval, raw_data)\u001b[0m\n\u001b[1;32m    165\u001b[0m auroc_list, accuracy_list \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_dataset, test_dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(train_datasets, test_datasets):\n\u001b[0;32m--> 167\u001b[0m     auroc, accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_on_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_priority\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_priority\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     auroc_list\u001b[38;5;241m.\u001b[39mappend(auroc)\n\u001b[1;32m    169\u001b[0m     accuracy_list\u001b[38;5;241m.\u001b[39mappend(accuracy)\n",
      "File \u001b[0;32m/net/vast-storage/scratch/vast/yanglab/zaho/bfm/evaluation/neuroprobe_tasks.py:112\u001b[0m, in \u001b[0;36mFrozenModelEvaluation_SS_SM._evaluate_on_dataset\u001b[0;34m(self, subject, trial_id, train_dataset, test_dataset, log_priority, raw_data)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Generate features for training data\u001b[39;00m\n\u001b[1;32m    111\u001b[0m log(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerating frozen train features\u001b[39m\u001b[38;5;124m'\u001b[39m, priority\u001b[38;5;241m=\u001b[39mlog_priority, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 112\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_frozen_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubject_identifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_priority\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_priority\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_data\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m log(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone generating frozen train features\u001b[39m\u001b[38;5;124m'\u001b[39m, priority\u001b[38;5;241m=\u001b[39mlog_priority, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# Generate features for test data\u001b[39;00m\n",
      "File \u001b[0;32m/net/vast-storage/scratch/vast/yanglab/zaho/bfm/evaluation/neuroprobe_tasks.py:90\u001b[0m, in \u001b[0;36mFrozenModelEvaluation_SS_SM._generate_frozen_features\u001b[0;34m(self, dataloader, subject_identifier, trial_id, log_priority, raw_data)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m preprocess_function \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_preprocess_functions:\n\u001b[1;32m     89\u001b[0m         batch \u001b[38;5;241m=\u001b[39m preprocess_function(batch)\n\u001b[0;32m---> 90\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_evaluation_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(batch_input\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     92\u001b[0m log(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone generating frozen features for batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataloader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, priority\u001b[38;5;241m=\u001b[39mlog_priority, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     93\u001b[0m X\u001b[38;5;241m.\u001b[39mappend(features\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "Cell \u001b[0;32mIn[31], line 13\u001b[0m, in \u001b[0;36mretrieve_frozen_features\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     11\u001b[0m need_indices \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(need_indices\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mindices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m(need_indices))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_features[indices\u001b[38;5;241m.\u001b[39mindex(need_indices)]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "def retrieve_frozen_features(batch):\n",
    "    # INPUT:\n",
    "    #   batch['data'] shape: (batch_size, n_electrodes, n_timesamples)\n",
    "    #   batch['electrode_labels'] shape: list of length 1 (since it's the same across the batch), each element is a list of electrode labels\n",
    "    #   batch['metadata']: dictionary containing metadata like the subject identifier and trial id, sampling rate, etc.\n",
    "    # OUTPUT:\n",
    "    #   features shape: (batch_size, *) where * can be arbitrary (and will be concatenated for regression)\n",
    "    indices = precomputed_features[batch['metadata']['subject_identifier'], batch['metadata']['trial_id']]['indices']\n",
    "    frozen_features = precomputed_features[batch['metadata']['subject_identifier'], batch['metadata']['trial_id']]['frozen_features']\n",
    "\n",
    "    need_indices = batch['data'][0]\n",
    "    print(need_indices.shape)\n",
    "    print(indices.index(need_indices))\n",
    "\n",
    "    return frozen_features[indices.index(need_indices)]\n",
    "\n",
    "evaluation.model_evaluation_function = retrieve_frozen_features\n",
    "evaluation.model_preprocess_functions = []\n",
    "evaluation.batch_size = 400\n",
    "\n",
    "epoch0_eval_results = evaluation.evaluate_on_all_metrics(log_priority=3, quick_eval=False, raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BFM IC2 (.venv)",
   "language": "python",
   "name": "bfm_ic2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
